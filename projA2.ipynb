{"cells":[{"cell_type":"markdown","metadata":{},"source":["<br>\n","\n","<hr style=\"border: 1px solid #fdb515;\" />\n","\n","# Question 5\n","\n","It is time to build your own model!\n","\n","You will conduct feature engineering on your training data using the `feature_engine_final` function (you will define this in `q5d`), fit the model with this training data, and compute the training Root Mean Squared Error (RMSE). Then, we will process our test data with `feature_engine_final`, use the model to predict `Log Sale Price` for the test data, transform the predicted and original log values back into their original forms (by using `delog`), and compute the test RMSE.\n","\n","Your goal in Question 5 is to:\n","\n","* Define a function to perform feature engineering and produce a design matrix for modeling.\n","* Apply this feature engineering function to the training data and use it to train a model that can predict the `Log Sale Price` of houses.\n","* Use this trained model to predict the `Log Sale Price`s of the test set. Remember that our test set does not contain the true `Sale Price` of each house –— your model is trying to guess them! \n","* Submit your predicted `Log Sale Price`s on the test set to Gradescope."]},{"cell_type":"code","execution_count":39,"metadata":{"trusted":false},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn import linear_model as lm\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from ds100_utils import *\n","from feature_func import *\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","eda_data = pd.read_csv(\"cook_county_train_val.csv\", index_col='Unnamed: 0')"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false},"source":["<br>\n","\n","---\n","\n","## Question 5c: Defining Helper Function or Helper Variables"]},{"cell_type":"code","execution_count":41,"metadata":{"trusted":false},"outputs":[],"source":["ordinal_cols = ['Repair Condition',  \"Garage 1 Size\"]\n","\n","sparse = ['Town and Neighborhood'] \n","\n","# one_hot_cols = [\"Property Class\", \"Garage 1 Area\"] \n","\n","one_hot_cols = [] \n","\n","binary = [\"Central Air\", \n","          \"O'Hare Noise\",\n","          \"Floodplain\",\n","          \"Road Proximity\",\n","          \"Most Recent Sale\",\n","          'Pure Market Filter']\n","\n","qualitative = ['Land Square Feet', \n","               \"Fireplaces\", \n","               \"Building Square Feet\",\n","               \"Estimate (Land)\",\n","               \"Estimate (Building)\",\n","               \"Age\",\n","               \"Longitude\",\n","               \"Latitude\",\n","               'Lot Size']\n","\n","X_features = ordinal_cols + sparse + one_hot_cols + binary + qualitative\n","drop_these_cols = list(set(eda_data.columns).difference(set(X_features)))\n","drop_these_cols.remove('Sale Price')"]},{"cell_type":"code","execution_count":43,"metadata":{"trusted":false},"outputs":[],"source":["#target encoding\n","eda_data['Sale Price'].describe()\n","(3.120000e+05 - 4.520000e+04) * 1.5 + 3.120000e+05\n","np.sum(eda_data['Sale Price'] > 712200.0)\n","#10000000.0\n","def remove_upper_outlier(df):\n","    data = df.copy()\n","    data = data[data['Sale Price'] < 10000000.0]\n","    data = data.reset_index(drop=True)\n","    return data\n","    \n","eda_data_v2 = remove_outliers(eda_data, 'Sale Price', lower=500)\n","eda_data_v2 = remove_upper_outlier(eda_data_v2)\n","\n","target_enc_columns = ['Town and Neighborhood']\n","\n","log_required = [\"Land Square Feet\", \"Building Square Feet\", \"Estimate (Land)\", \"Estimate (Building)\"] \n","\n","col_and_mean = {}\n","col_and_mapping = {}\n","for col in target_enc_columns:\n","    mapping = dict(eda_data_v2.groupby(col)['Sale Price'].mean())\n","    m = np.mean(list(mapping.values()))\n","    col_and_mean[col] = m\n","    col_and_mapping[col] = mapping\n","\n","def add_target_enc(df):\n","    data = df.copy()\n","    for col in target_enc_columns:\n","        mapper = col_and_mapping[col]\n","        meaner = col_and_mean[col]\n","        data[col] = data[col].map(mapper, na_action='ignore')\n","        data[col] = data[col].fillna(meaner)\n","        data[col] = np.log(data[col])\n","    return data\n","    \n","log_required = [\"Land Square Feet\", \"Building Square Feet\", \"Estimate (Land)\", \"Estimate (Building)\"] \n","\n","OneHotEncoders = {}\n","for col in one_hot_cols:\n","    ohe = OneHotEncoder(handle_unknown='ignore')   \n","    ohe.fit(eda_data[[col]])    \n","    OneHotEncoders[col] = ohe\n","\n","def add_one_hot(df):\n","    data = df.copy()\n","    for col in one_hot_cols:\n","        ohe = OneHotEncoders[col]\n","        encoded_day = ohe.transform(data[[col]]).toarray()\n","        encoded_day_df = pd.DataFrame(encoded_day, columns=ohe.get_feature_names_out())\n","        data = data.join(encoded_day_df).drop(columns=col)\n","    return data\n","\n","def qualitative_engin(df):\n","    data = df.copy()\n","    for col in log_required:\n","        if data[col].min() <= 0:\n","            data[col] = data[col] + 0.1\n","        data[col] = np.log(data[col])\n","    return data\n","\n","def feature_pipeline(df):\n","    data = df.copy()\n","    data = qualitative_engin(add_target_enc(data))\n","    data = data.fillna(0.0)\n","    return data\n","\n","def add_story(data):\n","    with_rooms = data.copy()\n","    with_rooms['story'] = with_rooms['Description'].str.findall(r\"([a-zA-Z]+)-story[\\w\\s]*houeshold\").str[0]\n","    mapping = {'one':1.0, 'two':2.0, 'three':3.0}\n","    with_rooms['story'] = with_rooms['story'].map(mapping, na_action='ignore')\n","    with_rooms['story'] = with_rooms['story'].fillna(1.0)\n","    return with_rooms\n","\n","def add_bathroom(data):\n","    with_rooms = data.copy()\n","    with_rooms['bath_rooms'] = with_rooms['Description'].str.findall(r\"([0-9]{1}\\.[0-9]{1}) of which are bathrooms\").str[0].apply(lambda x : float(x))\n","    return with_rooms"]},{"cell_type":"code","execution_count":45,"metadata":{"tags":[],"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Current training RMSE: 143770.44039927263\n","You can check your grade for your prediction as per the grading scheme outlined at the start of Question 5\n"]}],"source":["def feature_engine_final(data, is_test_set=False):\n","    if not is_test_set:\n","        data = data.reset_index(drop=True)\n","        data = remove_outliers(data, 'Sale Price', lower=10000)\n","        data = data.reset_index(drop=True)\n","        data = remove_upper_outlier(data)\n","        data = data.reset_index(drop=True)\n","        data['Log Sale Price'] = np.log(data['Sale Price'])\n","        data = add_story(data)\n","        data = add_bathroom(data)\n","        data = add_total_bedrooms(data)\n","        data = feature_pipeline(data)\n","    else:\n","        data = data.reset_index(drop=True)\n","        data = add_story(data)\n","        data = add_bathroom(data)\n","        data = add_total_bedrooms(data)\n","        data = feature_pipeline(data)\n","    scaler = StandardScaler()\n","    if is_test_set:\n","        X = data.drop(drop_these_cols, axis=1, errors='ignore')\n","        X_hot = add_one_hot(X[one_hot_cols]).to_numpy()\n","        X_scaler = scaler.fit_transform(X.drop(one_hot_cols, axis=1, errors='ignore'))\n","        X = np.concatenate((X_scaler, X_hot), axis=1)\n","        return X\n","    else:\n","        drop_these_cols_v2 = drop_these_cols\n","        drop_these_cols_v2 = drop_these_cols_v2 + ['Sale Price', 'Log Sale Price']\n","        X = data.drop(drop_these_cols_v2, axis=1, errors='ignore')\n","        X_hot = add_one_hot(X[one_hot_cols]).to_numpy()\n","        X_scaler = scaler.fit_transform(X.drop(one_hot_cols, axis=1))\n","        X = np.concatenate((X_scaler, X_hot), axis=1)\n","        Y = data['Log Sale Price']  \n","        return X, Y\n","\n","check_rmse_threshold = run_linear_regression_test_optim(lm.LinearRegression(fit_intercept=True), feature_engine_final, 'cook_county_train.csv', None, False)\n","print(\"Current training RMSE:\", check_rmse_threshold.loss)\n","print(\"You can check your grade for your prediction as per the grading scheme outlined at the start of Question 5\")"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false},"source":["<br>\n","\n","---\n","\n","## Question 5e: Fit and Evaluate your Model\n","\n","**This question is not graded.** Use this space below to evaluate your models. Some ideas are listed below. \n","\n","**Note:** While we have a grader function that checks RMSE for you, it is best to define and create your own model object and fit on your data. This way, you have access to the model directly to help you evaluate/debug if needed. For this project, you should use a `sklearn` default `LinearRegression()` model with intercept term for grading purposes. Do not modify any hyperparameter in `LinearRegression()`, and focus on feature selection or hyperparameters of your own feature engineering function.\n","\n","It may also be helpful to calculate the RMSE directly as follows:\n","\n","$$RMSE = \\sqrt{\\dfrac{\\sum_{\\text{houses in the set}}(\\text{actual price for house} - \\text{predicted price for house})^2}{\\text{number of houses}}}$$\n","\n","A function that computes the RMSE is provided below. Feel free to use it if you would like calculate the RMSE for your training set."]},{"cell_type":"code","execution_count":47,"metadata":{"deletable":false,"editable":false,"trusted":false},"outputs":[],"source":["def rmse(predicted, actual):\n","    \"\"\"\n","    Calculates RMSE from actual and predicted values.\n","    Input:\n","      predicted (1D array): Vector of predicted/fitted values\n","      actual (1D array): Vector of actual values\n","    Output:\n","      A float, the RMSE value.\n","    \"\"\"\n","    return np.sqrt(np.mean((actual - predicted)**2))"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false},"source":["<br>\n","\n","---\n","\n","## Question 5f Submission\n","\n","Recall that the test set given to you in this assignment does not contain values for the true `Sale Price` of each house. You will be predicting `Log Sale Price` on the data stored in `cook_county_contest_test.csv`. To determine your model's RMSE on the test set, you will submit the predictions made by your model to Gradescope. There, we will run checks to see what your test RMSE is by considering (hidden) true values for the `Sale Price`. We will delog/exponentiate your prediction on Gradescope to compute RMSE and use this to score your model. Before submitting to Gradescope, make sure that your predicted values can all be delogged (i.e., if one of your `Log Sale Price` predictions is 60, it is too large; $e^{60}$ is too big!)\n","\n","Your score on this section will be determined by the grading scheme outlined at the start of Question 5. **Remember that you can only submit your test set predictions to Gradescope up to 4 times per day. Plan your time to ensure that you can adjust your model as necessary, and please test your model's performance using cross-validation before making any submissions.** For more on cross-validation, check [Lecture 16](https://ds100.org/sp24/lecture/lec16/). In particular, the [Lecture 16 notebook](https://data100.datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FDS-100%2Fsp24-student&urlpath=lab%2Ftree%2Fsp24-student%2F%2Flecture%2Flec16%2Flec16.ipynb&branch=main) may be helpful here. You can also feel free to reference what you did in previous questions when creating training and validation sets and seeing how your model performs.\n","\n","To determine the error on the test set, please submit your predictions on the test set to the Gradescope assignment **Project A2 Test Set Predictions**. The CSV file to submit is generated below, and you should not modify the cell below. Simply download the CSV file, and submit it to the appropriate Gradescope assignment.\n","\n","**You will not receive credit for the test set predictions (i.e., up to 3 points) unless you submit to this assignment**!!\n","\n","**Note:** If you run into any errors, the [Proj. A2 Common Mistakes](https://ds100.org/debugging-guide/projA2/projA2.html) section of the [Data 100 Debugging Guide](https://ds100.org/debugging-guide) may be a helpful resource."]},{"cell_type":"code","execution_count":49,"metadata":{"deletable":false,"editable":false,"trusted":false},"outputs":[{"data":{"text/html":["Download your test prediction <a href='submission_20240318_184751.csv' download>here</a>."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["You may now upload this CSV file to Gradescope for scoring.\n"]}],"source":["from datetime import datetime\n","from IPython.display import display, HTML\n","\n","Y_test_pred = run_linear_regression_test(lm.LinearRegression(fit_intercept=True), feature_engine_final, None, 'cook_county_train.csv', 'cook_county_contest_test.csv', \n","                                         is_test = True, is_ranking = False, return_predictions = True\n","                                         )\n","\n","# Construct and save the submission:\n","submission_df = pd.DataFrame({\n","    \"Id\": pd.read_csv('cook_county_contest_test.csv')['Unnamed: 0'], \n","    \"Value\": Y_test_pred,\n","}, columns=['Id', 'Value'])\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","filename = \"submission_{}.csv\".format(timestamp)\n","submission_df.to_csv(filename, index=False)\n","\n","#print('Created a CSV file: {}.'.format(\"submission_{}.csv\".format(timestamp)))\n","display(HTML(\"Download your test prediction <a href='\" + filename + \"' download>here</a>.\"))\n","print('You may now upload this CSV file to Gradescope for scoring.')#"]},{"cell_type":"code","execution_count":50,"metadata":{"deletable":false,"editable":false,"trusted":false},"outputs":[{"data":{"text/plain":["count    55311.000000\n","mean        12.200539\n","std          0.837872\n","min          9.281137\n","25%         11.612339\n","50%         12.168546\n","75%         12.741449\n","max         15.907689\n","Name: Value, dtype: float64"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["# Scratch space to check if your prediction is reasonable. See 5e for hints. \n","# We will not reset the submission count for mis-submission issues.\n","submission_df[\"Value\"].describe()"]},{"cell_type":"markdown","metadata":{},"source":["Congratulations on finishing your prediction model for home sale prices in Cook County! In the following section, we'll delve deeper into the implications of predictive modeling within the CCAO case study, especially because statistical modeling is how the CCAO valuates properties. \n","\n","Refer to [Lecture 15](https://ds100.org/sp24/lecture/lec15/) if you're having trouble getting started!"]}],"metadata":{"celltoolbar":"Create Assignment","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"otter":{"OK_FORMAT":true,"require_no_pdf_confirmation":true,"tests":{"q1c":{"name":"q1c","points":1,"suites":[{"cases":[{"code":">>> q1c.lower() in ['a', 'b', 'c']\nTrue","hidden":false,"locked":false}],"scored":true,"setup":"","teardown":"","type":"doctest"}]},"q2":{"name":"q2","points":2,"suites":[{"cases":[{"code":">>> train.shape == (163833, 62)\nTrue","hidden":false,"locked":false},{"code":">>> validation.shape == (40959, 62)\nTrue","hidden":false,"locked":false},{"code":">>> np.isclose(train['Sale Price'].mean(), 244939.22668204817, atol=0.1)\nTrue","hidden":false,"locked":false},{"code":">>> np.allclose(validation.index[-5:], [153946, 117415, 9448, 188605, 3223])\nTrue","hidden":false,"locked":false},{"code":">>> np.isclose(validation['Sale Price'].mean(), 246066.1821089382, atol=0.1)\nTrue","hidden":false,"locked":false}],"scored":true,"setup":"","teardown":"","type":"doctest"}]},"q3a":{"name":"q3a","points":2,"suites":[{"cases":[{"code":">>> (q3a in ['>=', '=', '<=']) == True\nTrue","hidden":false,"locked":false},{"code":">>> q3a == '>='\nTrue","hidden":false,"locked":false}],"scored":true,"setup":"","teardown":"","type":"doctest"}]},"q3b":{"name":"q3b","points":3,"suites":[{"cases":[{"code":">>> isinstance(X_train_m1, pd.core.frame.DataFrame) and isinstance(Y_train_m1, pd.core.series.Series) and isinstance(X_valid_m1, pd.core.frame.DataFrame) and isinstance(Y_valid_m1, pd.core.series.Series) and isinstance(X_train_m2, pd.core.frame.DataFrame) and isinstance(Y_train_m2, pd.core.series.Series) and isinstance(X_valid_m2, pd.core.frame.DataFrame) and isinstance(Y_valid_m2, pd.core.series.Series)\nTrue","hidden":false,"locked":false},{"code":">>> assert len(m2_pipelines) == 5\n>>> assert log_transform in set([p[0] for p in m2_pipelines])\n","hidden":false,"locked":false}],"scored":true,"setup":"","teardown":"","type":"doctest"}]},"q3c":{"name":"q3c","points":2,"suites":[{"cases":[{"code":">>> np.isclose(Y_fitted_m1.max(), 17.528601849438104, atol=0.0001) == True\nTrue","hidden":false,"locked":false},{"code":">>> np.isclose(Y_fitted_m2.max(), 15.614096224439168, atol=0.0001) == True\nTrue","hidden":false,"locked":false},{"code":">>> np.isclose(Y_predicted_m1.max(), 15.540922864181525, atol=0.0001) == True\nTrue","hidden":false,"locked":false},{"code":">>> np.isclose(Y_predicted_m2.max(), 15.02563963305767, atol=0.0001) == True\nTrue","hidden":false,"locked":false}],"scored":true,"setup":"","teardown":"","type":"doctest"}]},"q4b":{"name":"q4b","points":1,"suites":[{"cases":[{"code":">>> q4b.lower() in ['regressive', 'fair', 'progressive']\nTrue","hidden":false,"locked":false}],"scored":true,"setup":"","teardown":"","type":"doctest"}]},"q5d":{"name":"q5d","points":3,"suites":[{"cases":[{"code":">>> check_rmse_threshold(200000)\nTrue","hidden":false,"locked":false},{"code":">>> check_rmse_threshold(240000)\nTrue","hidden":false,"locked":false},{"code":">>> check_rmse_threshold(280000)\nTrue","hidden":false,"locked":false},{"code":">>> check_rmse_threshold.signature == (feature_engine_final, 'cook_county_train.csv', None)\nTrue","hidden":false,"locked":false}],"scored":true,"setup":"","teardown":"","type":"doctest"}]},"q6a":{"name":"q6a","points":1,"suites":[{"cases":[{"code":">>> rmse_cheap >= 0\nTrue","hidden":false,"locked":false},{"code":">>> rmse_expensive >= 0\nTrue","hidden":false,"locked":false},{"code":">>> 0 <= prop_overest_cheap <= 1\nTrue","hidden":false,"locked":false},{"code":">>> 0 <= prop_overest_expensive <= 1\nTrue","hidden":false,"locked":false}],"scored":true,"setup":"","teardown":"","type":"doctest"}]},"q6b":{"name":"q6b","points":2,"suites":[{"cases":[{"code":">>> prop_overest_interval(preds_df, 10, 14) >= 0 and prop_overest_interval(preds_df, 10, 14) <= 1\nTrue","hidden":false,"locked":false},{"code":">>> rmse_interval(preds_df, 10, 14) < 1000000000.0 and rmse_interval(preds_df, 10, 14) > 0\nTrue","hidden":false,"locked":false}],"scored":true,"setup":"","teardown":"","type":"doctest"}]}}}},"nbformat":4,"nbformat_minor":4}
